\subsection{Lexer}

The \lexer{} processes the source code as a stream of characters. Once it identifies
a valid lexeme, it emits the corresponding token. Specifically, the \lexer{} follows
the \textit{Maximal Munch} rule, recognizing the longest verified lexeme, ensuring
that tokens represent the most appropriate grouping of characters. In fine, the
\lexer{} transforms a stream of characters into a stream of tokens.

